\section{Background}
\begin{enumerate}
    \item \textbf{Existing educational support systems and their limitations}, like how~\citet{Garrido2009} cannot monitor the learning routes, similar to intelligent tutoring systems;~\citet{Rojas2022} covers collaborative problem-solving and providing feedback in real-time, but does not necessarily provide an application to a classroom.
    \item \textbf{Overview of related work in the field of using AI and planning for educational assistance}~\cite{Castillo2009} summary.
    \item \textbf{The specific challenges faced by secondary education that necessitate innovative solutions}, diversity of learning styles and technological integration of learning solutions \textbf{TODO: Find Material}.
\end{enumerate}

\subsubsection{Goal Recognition}
Classical planning, as discussed in \citet{Fox2003}, treats time as relative and considers only causal dependencies among actions. However, real-world problems often entail complexities, including temporal aspects, numerical values, stochastic effects, and dynamic environments. Numeric planning extends classical planning by incorporating numeric state variables and utilising languages such as PDDL 2.1~\cite{Fox2003} and PDDL+~\cite{Fox2006}. These formalisms enable the representation of time-dependent changes, either as discrete time-dependent effects of durative actions or continuous process-dependent alterations. PDDL+ serves as an extension of PDDL designed specifically to model hybrid systems by integrating continuous processes and events, as outlined by~\citet{Haslum2019}. Its primary purpose is to facilitate the representation of planning domains that combine discrete and continuous elements.

Introduced in \citet{Scala2016} and \citet{ScalaHaslum2016}, the Expressive Numeric Heuristic Search Planner (ENHSP) is compatible with both PDDL 2.1 and PDDL+. ENHSP operates as a forward heuristic search planner, converting PDDL into an asymptotic relaxed planning graph. In this graph, nodes correspond to states explored by the planner, and a heuristic function guides the search process. This function directs the exploration towards nodes whose associated states are reachable from the initial state and bring the system closer to the desired goals.

\subsubsection{Theoretical Framework} 
In automated planning, the use of predicates and objects allow us to represent and reason about the world, what tasks may need to be carried out in that world, and what goals are achievable in the context of that world.
A predicate $\predicate\in\predicates$ is denoted by an n-ary predicate symbol, applied to a sequence of zero or more terms $\term_0,\dots,\term_n$. Terms are either constants or variables. We can refer to ground predicates, which represent logical values according to some interpretation as facts, which are divided into two types: positive and negated; as well as having constants for truth and false ($\top$ and $\bot$ respectively).
Now that we have defined a formal element for individual facts of the environment, we aggregate those which are relevant into a state.
A state $\states$ is a finite set of positive facts $\fact$ which follow the closed-world assumption. It follows that $\fact$ is true in $\states$ if $\fact\in\states$. We are also able to assume a simple inference relation; such that $\states\models\fact$ \textit{iff} $\fact\in\states,\states\not\models\fact$ \textit{iff} $\fact\not\in\states$, and $\states\models\bigwedge^{\size{\facts}}_{n=0}\fact_n$ \textit{iff} $\set{\fact_0,\dots,\fact_n}\supseteq\states$.
Planning domains describe the dynamics of an environment by employing operators characterised by a restricted first-order logical representation, creating schemata for actions aimed at altering the state. A schema is a template that offers a broad overview of task completion. It acts as a blueprint for a series of actions in different scenarios, allowing for the capture of common strategies for achieving goals. These schema templates promote knowledge reuse and adaptation, making problem-solving more efficient by tailoring abstract plans to the current context.
An operator $\action$ is represented through a tuple $\tuple{\name(\action),\pre(\action),\eff(\action)}$; where $\name(\action)$ represents the signature or description of $\action$; $\pre(\action)$ describes the preconditions of $\action$~and $\eff(\action)$ represents the effects of~$\action$. $\eff(\action)^+$ and $\eff(\action)^-$ divides $\eff(\action)$ into an add-list of positive predicates and a delete-list of negated predicates respectively. An action is a ground operator instantiated over its free variables. 
An action $\action$ is applicable to \states~if and only if $\states\models\pre(\action)$, and generates a new state $\states'$, such that $\states'\coloneqq(\states\cup\eff(\action)^+/\eff(\action)^-)$. 
A pair $\tuple{\facts,\actions}$ represents a planning domain definition $\planningdomain$, specifying the knowledge of the domain model, consisting of a finite set of facts and a finite set of actions (represented by $\facts$ and $\actions$ respectively).
Planning instances comprise both the planning domain and the planning problem, describing a finite set of objects of the environment. These are the initial state, and the goal state, which represent where the agent(s) would start and finish.
A planning instance $\planninginstance$ is represented by a tuple $\tuple{\planningdomain,\initial,\goals}$, whereby $\planningdomain=\tuple{\facts,\actions}$ represents the domain definition; $\initial\supseteq\facts$ is the initial state specification, defined through specifying the value for all facts in the initial state; and $\goals\supseteq\facts$ is the goal state specification, representing a singular goal, or a set of goals (that may be extremely large) satisfying the goal specification of the desired state to be achieved.
Classical planning representations often separate the definition of the initial state ($\initial$) and the goal state ($\goals$) as part of a planning problem ($\planningdomain$) to be utilised with a domain, such as STRIPS~\cite{Fikes1971} or PDDL~\cite{PDDL1998}.
For a planning instance $\planninginstance=\tuple{\planningdomain,\initial,\goals}$, a plan $\plan$ is a sequence of actions $\tuple{\action_0,\dots,\action_n}$ modifying the initial state $\initial$ into a state $\states\models\goals$, whereby the goal state $\goals$ holds by the successive execution of actions in a plan $\plan$. A plan is optimal ($\optimalplan$) with a length $\vert\optimalplan\vert$ if there exists no other plan $\plan'$ for $\planninginstance~\vert~ \plan'<\plan$.
Actions may have an associated cost applied to them. If an action does not have an associated cost, it is assumed to  have the unit cost ($1$) assigned to it. 
A plan ($\plan$) is optimal if its cost and respective length meets the evaluation criterion \textemdash~whether that's minimal, maximal, or otherwise.
A goal recognition task is a tuple $\recognitionproblem=\tuple{\planningdomain,\initial,\goals,\observationsequence}$; such that $\planningdomain=\tuple{\facts,\actions}$ is a planning domain definition; $\initial$ is the initial state; $\goals$ is the set of possible goals, also assuming the inclusion of some correct hidden goal $\hiddengoal$ ($\hiddengoal\in\goals$); and $\observationsequence=\tuple{\observation_0,\dots,\observation_n}$ is an observation sequence of executed actions. The observation sequence $\observationsequence$ is satisfied by a valid plan $\plan$, following that with each observation $\observation_i=\name(\action), \action\in\actions$, with $\action$ being part of $\plan$, and that plan $\plan$ transitioning $\initial$ into $\hiddengoal$ through the sequential execution of actions in $\plan$.
The optimal solution to a goal recognition task may consist of a singleton set that exclusively contains the correct hidden goal ($\hiddengoal\in\goals$) achieved by the observation sequence $\observationsequence$ of a plan execution.  In this context, we consider a solution suboptimal if it includes more than one goal, as all such goals are equally probable.
The solution to a goal recognition task $\recognitionproblem=\tuple{\planningdomain,\initial,\goals,\observationsequence}$ is a non-empty subset of the set of possible goals $\goalsolution\supseteq G~\vert~\forall G\in\goalsolution$, there exists a plan $\goalplan$ generated from a planning instance, and the observation sequence $\observationsequence$ is satisfied by $\goalplan$.