\section{Background}
\begin{enumerate}
    \item \textbf{Overview of related work in the field of using AI and planning for educational assistance}~\cite{Castillo2009} summary.
    \item \textbf{The specific challenges faced by secondary education that necessitate innovative solutions}, diversity of learning styles and technological integration of learning solutions \textbf{TODO\@: Find Material}.
\end{enumerate}

\subsubsection{Adaptive Learning and Intelligent Tutoring Systems} Adaptive learning systems provide personalised learning experiences. They adapt educational content and activities to the specific needs and abilities of each individual learner using AI algorithms. Key features of adaptive learning include:

\begin{itemize}
    \item Personalisation: Adaptive learning systems create a unique learning path for each student by adjusting content and pacing based on real-time performance data, as discussed in~\citet{ElSabagh2021}.
    
    \item Immediate Feedback: These systems offer instant feedback, helping students identify and address mistakes as they occur, leading to a deeper understanding of the material. [Citation Required]
    
    \item Data-Driven Insights: Adaptive learning systems collect and analyse data on student interactions, providing educators with valuable insights into student progress and areas requiring attention. [Citation Required]
\end{itemize}

\textbf{Limitations:}
\begin{itemize}
    \item Content Quality: The effectiveness of adaptive learning heavily depends on the quality of the learning materials. Inaccurate or outdated content may hinder personalisation efforts. [Citation Required]
    
    \item Overemphasis on Data: Overreliance on data and algorithms can result in a mechanistic approach to education, potentially overlooking the importance of the human element.~\citet{Rojas2022} covers collaborative problem-solving and providing feedback in real-time, but does not necessarily provide an application to a classroom.
    
    \item Resource Requirements: Implementing adaptive learning systems requires significant investments in technology and content development, which can be a barrier for institutions with limited resources. [Citation Required]
\end{itemize}

Intelligent Tutoring Systems simulate one-on-one tutoring experiences for students, using AI planning techniques to provide real-time guidance and adapt instructional approaches. Key features of ITS include:

\begin{itemize}
    \item Real-time Guidance: ITS offers students immediate feedback, clarifications, and guidance as they work through problems or assignments. [Citation Required]
    
    \item Step-by-Step Assistance: In subjects requiring sequential problem-solving, ITS provides step-by-step assistance, helping students grasp complex concepts. [Citation Required]
    
    \item Performance Assessment: ITS continuously assesses a student's knowledge and skills, offering targeted practice exercises and content based on their performance. [Citation Required]
\end{itemize}

\textbf{Limitations of Intelligent Tutoring Systems}
\begin{itemize}
    \item Lack of Contextual Understanding: ITS may lack a deep understanding of the broader context of learning, potentially leading to recommendations that are technically correct but not pedagogically appropriate.~\citet{Garrido2009} cannot monitor learning routes.
    
    \item Complex Development: Developing effective ITS can be complex and costly, requiring significant resources and expertise in algorithm development and content creation~\cite{Corbett1997}.
    
    \item Technology Access: Like adaptive learning, the effectiveness of ITS relies on technology access, which may not be equally available to all students. [Citation Required]
\end{itemize}

\subsubsection{Goal Recognition}
Classical planning, as discussed in \citet{Fox2003}, treats time as relative and considers only causal dependencies among actions. However, real-world problems often entail complexities, including temporal aspects, numerical values, stochastic effects, and dynamic environments. Numeric planning extends classical planning by incorporating numeric state variables and utilising languages such as PDDL 2.1~\cite{Fox2003} and PDDL+~\cite{Fox2006}. These formalisms enable the representation of time-dependent changes, either as discrete time-dependent effects of durative actions or continuous process-dependent alterations. PDDL+ serves as an extension of PDDL designed specifically to model hybrid systems by integrating continuous processes and events, as outlined by~\citet{Haslum2019}. Its primary purpose is to facilitate the representation of planning domains that combine discrete and continuous elements.

Introduced in \citet{Scala2016} and \citet{ScalaHaslum2016}, the Expressive Numeric Heuristic Search Planner (ENHSP) is compatible with both PDDL 2.1 and PDDL+. ENHSP operates as a forward heuristic search planner, converting PDDL into an asymptotic relaxed planning graph. In this graph, nodes correspond to states explored by the planner, and a heuristic function guides the search process. This function directs the exploration towards nodes whose associated states are reachable from the initial state and bring the system closer to the desired goals.

\subsubsection{Theoretical Framework} 
In automated planning, the use of predicates and objects allow us to represent and reason about the world, what tasks may need to be carried out in that world, and what goals are achievable in the context of that world.
A predicate $\predicate\in\predicates$ is denoted by an n-ary predicate symbol, applied to a sequence of zero or more terms $\term_0,\dots,\term_n$. Terms are either constants or variables. We can refer to ground predicates, which represent logical values according to some interpretation as facts, which are divided into two types: positive and negated; as well as having constants for truth and false ($\top$ and $\bot$ respectively).
Now that we have defined a formal element for individual facts of the environment, we aggregate those which are relevant into a state.
A state $\states$ is a finite set of positive facts $\fact$ which follow the closed-world assumption. It follows that $\fact$ is true in $\states$ if $\fact\in\states$. We are also able to assume a simple inference relation; such that $\states\models\fact$ \textit{iff} $\fact\in\states,\states\not\models\fact$ \textit{iff} $\fact\not\in\states$, and $\states\models\bigwedge^{\size{\facts}}_{n=0}\fact_n$ \textit{iff} $\set{\fact_0,\dots,\fact_n}\supseteq\states$.
Planning domains describe the dynamics of an environment by employing operators characterised by a restricted first-order logical representation, creating schemata for actions aimed at altering the state. A schema is a template that offers a broad overview of task completion. It acts as a blueprint for a series of actions in different scenarios, allowing for the capture of common strategies for achieving goals. These schema templates promote knowledge reuse and adaptation, making problem-solving more efficient by tailoring abstract plans to the current context.
An operator $\action$ is represented through a tuple $\tuple{\name(\action),\pre(\action),\eff(\action)}$; where $\name(\action)$ represents the signature or description of $\action$; $\pre(\action)$ describes the preconditions of $\action$~and $\eff(\action)$ represents the effects of~$\action$. $\eff(\action)^+$ and $\eff(\action)^-$ divides $\eff(\action)$ into an add-list of positive predicates and a delete-list of negated predicates respectively. An action is a ground operator instantiated over its free variables. 
An action $\action$ is applicable to \states~if and only if $\states\models\pre(\action)$, and generates a new state $\states'$, such that $\states'\coloneqq(\states\cup\eff(\action)^+/\eff(\action)^-)$. 
A pair $\tuple{\facts,\actions}$ represents a planning domain definition $\planningdomain$, specifying the knowledge of the domain model, consisting of a finite set of facts and a finite set of actions (represented by $\facts$ and $\actions$ respectively).
Planning instances comprise both the planning domain and the planning problem, describing a finite set of objects of the environment. These are the initial state, and the goal state, which represent where the agent(s) would start and finish.
A planning instance $\planninginstance$ is represented by a tuple $\tuple{\planningdomain,\initial,\goals}$, whereby $\planningdomain=\tuple{\facts,\actions}$ represents the domain definition; $\initial\supseteq\facts$ is the initial state specification, defined through specifying the value for all facts in the initial state; and $\goals\supseteq\facts$ is the goal state specification, representing a singular goal, or a set of goals (that may be extremely large) satisfying the goal specification of the desired state to be achieved.
Classical planning representations often separate the definition of the initial state ($\initial$) and the goal state ($\goals$) as part of a planning problem ($\planningdomain$) to be utilised with a domain, such as STRIPS~\cite{Fikes1971} or PDDL~\cite{PDDL1998}.
For a planning instance $\planninginstance=\tuple{\planningdomain,\initial,\goals}$, a plan $\plan$ is a sequence of actions $\tuple{\action_0,\dots,\action_n}$ modifying the initial state $\initial$ into a state $\states\models\goals$, whereby the goal state $\goals$ holds by the successive execution of actions in a plan $\plan$. A plan is optimal ($\optimalplan$) with a length $\vert\optimalplan\vert$ if there exists no other plan $\plan'$ for $\planninginstance~\vert~ \plan'<\plan$.
Actions may have an associated cost applied to them. If an action does not have an associated cost, it is assumed to  have the unit cost ($1$) assigned to it. 
A plan ($\plan$) is optimal if its cost and respective length meets the evaluation criterion \textemdash~whether that's minimal, maximal, or otherwise.
A goal recognition task is a tuple $\recognitionproblem=\tuple{\planningdomain,\initial,\goals,\observationsequence}$; such that $\planningdomain=\tuple{\facts,\actions}$ is a planning domain definition; $\initial$ is the initial state; $\goals$ is the set of possible goals, also assuming the inclusion of some correct hidden goal $\hiddengoal$ ($\hiddengoal\in\goals$); and $\observationsequence=\tuple{\observation_0,\dots,\observation_n}$ is an observation sequence of executed actions. The observation sequence $\observationsequence$ is satisfied by a valid plan $\plan$, following that with each observation $\observation_i=\name(\action), \action\in\actions$, with $\action$ being part of $\plan$, and that plan $\plan$ transitioning $\initial$ into $\hiddengoal$ through the sequential execution of actions in $\plan$.
The optimal solution to a goal recognition task may consist of a singleton set that exclusively contains the correct hidden goal ($\hiddengoal\in\goals$) achieved by the observation sequence $\observationsequence$ of a plan execution.  In this context, we consider a solution suboptimal if it includes more than one goal, as all such goals are equally probable.
The solution to a goal recognition task $\recognitionproblem=\tuple{\planningdomain,\initial,\goals,\observationsequence}$ is a non-empty subset of the set of possible goals $\goalsolution\supseteq G~\vert~\forall G\in\goalsolution$, there exists a plan $\goalplan$ generated from a planning instance, and the observation sequence $\observationsequence$ is satisfied by $\goalplan$.